{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nose.tools as nt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import regreg.api as rr\n",
    "\n",
    "from selectinf.randomized.group_lasso_query import (group_lasso,split_group_lasso)\n",
    "from selectinf.randomized.group_lasso_query_quasi import (group_lasso_quasi, split_group_lasso_quasi)\n",
    "\n",
    "# from selectinf.base import (selected_targets,selected_targets_quasi)\n",
    "from selectinf.randomized.tests.instance import (quasi_poisson_group_instance, poisson_group_instance)\n",
    "\n",
    "from selectinf.base import restricted_estimator\n",
    "from selectinf.randomized.tests.test_quasipoisson_group_lasso import calculate_F1_score, naive_inference, \\\n",
    "    randomization_inference, randomization_inference_poisson, data_splitting, test_comparison_quasipoisson_group_lasso_vary_s\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "def test_comparison_quasipoisson_group_lasso_vary_s(n=500,\n",
    "                                          p=200,\n",
    "                                          signal_fac=0.1,\n",
    "                                          s=5,\n",
    "                                          sigma=2,\n",
    "                                          rho=0.3,\n",
    "                                          randomizer_scale=1.,\n",
    "                                          full_dispersion=True,\n",
    "                                          level=0.90,\n",
    "                                          iter=1):\n",
    "    \"\"\"\n",
    "    Compare to R randomized lasso\n",
    "    \"\"\"\n",
    "\n",
    "    # Operating characteristics\n",
    "    oper_char = {}\n",
    "    oper_char[\"sparsity size\"] = []\n",
    "    oper_char[\"coverage rate\"] = []\n",
    "    oper_char[\"avg length\"] = []\n",
    "    oper_char[\"method\"] = []\n",
    "    oper_char[\"F1 score\"] = []\n",
    "    #oper_char[\"runtime\"] = []\n",
    "\n",
    "    confint_df = pd.DataFrame()\n",
    "\n",
    "    for s in [5, 8, 10]:  # [0.01, 0.03, 0.06, 0.1]:\n",
    "        for i in range(iter):\n",
    "            # np.random.seed(i)\n",
    "\n",
    "            # inst = quasi_poisson_group_instance\n",
    "            inst_p = poisson_group_instance\n",
    "            const = group_lasso_quasi.quasipoisson\n",
    "            const_split = split_group_lasso_quasi.quasipoisson\n",
    "\n",
    "            signal = np.sqrt(signal_fac * 2 * np.log(p))\n",
    "            signal_str = str(np.round(signal, decimals=2))\n",
    "\n",
    "            while True:  # run until we get some selection\n",
    "                groups = np.arange(50).repeat(4)\n",
    "                \"\"\"\n",
    "                X, Y, beta = inst(n=n,\n",
    "                                  p=p,\n",
    "                                  signal=signal,\n",
    "                                  sgroup=s,\n",
    "                                  groups=groups,\n",
    "                                  ndiscrete=0,\n",
    "                                  nlevels=0,\n",
    "                                  sdiscrete=0,  # s-3, # How many discrete rvs are not null\n",
    "                                  equicorrelated=False,\n",
    "                                  rho=rho,\n",
    "                                  phi=1.5,\n",
    "                                  random_signs=True,\n",
    "                                  center=False,\n",
    "                                  scale=True)[:3]\n",
    "                                  \"\"\"\n",
    "                # print(X)\n",
    "\n",
    "                X, Y, beta = inst_p(n=n,\n",
    "                                  p=p,\n",
    "                                  signal=signal,\n",
    "                                  sgroup=s,\n",
    "                                  groups=groups,\n",
    "                                  ndiscrete=0,\n",
    "                                  nlevels=0,\n",
    "                                  sdiscrete=0,  # s-3, # How many discrete rvs are not null\n",
    "                                  equicorrelated=False,\n",
    "                                  rho=rho,\n",
    "                                  random_signs=True,\n",
    "                                  center=False,\n",
    "                                  scale=True)[:3]\n",
    "\n",
    "                n, p = X.shape\n",
    "\n",
    "                noselection = False  # flag for a certain method having an empty selected set\n",
    "\n",
    "                \"\"\"\n",
    "                if not noselection:\n",
    "                    # carving\n",
    "                    coverage_s, length_s, beta_target_s, nonzero_s, \\\n",
    "                    selection_idx_s, K, conf_low_s, conf_up_s = \\\n",
    "                        split_inference(X=X, Y=Y, n=n, p=p,\n",
    "                                        beta=beta, groups=groups, const=const_split,\n",
    "                                        proportion=0.5)\n",
    "\n",
    "                    noselection = (coverage_s is None)\n",
    "                    if noselection:\n",
    "                        print('No selection for carving')\n",
    "                \"\"\"\n",
    "                if not noselection:\n",
    "                    # MLE inference\n",
    "                    coverage, length, beta_target, nonzero, conf_low, conf_up = \\\n",
    "                        randomization_inference(X=X, Y=Y, n=n, p=p, #proportion=0.5,\n",
    "                                                beta=beta, groups=groups)\n",
    "\n",
    "                    noselection = (coverage is None)\n",
    "                    print(\"MLE inference noselection:\", noselection)\n",
    "\n",
    "\n",
    "                \"\"\"# Poisson inference, to be deleted\n",
    "                if not noselection:\n",
    "                    # MLE inference (Poisson)\n",
    "                    coverage_p, length_p, beta_target_p, nonzero_p, conf_low_p, conf_up_p = \\\n",
    "                        randomization_inference_poisson(X=X, Y=Y, n=n, p=p, #proportion=0.5,\n",
    "                                                        beta=beta, groups=groups)\n",
    "                    noselection = (coverage_p is None)\"\"\"\n",
    "                \"\"\"\n",
    "                # Poisson data splitting, to be deleted\n",
    "                if not noselection:\n",
    "                    # data splitting\n",
    "                    coverage_dsp, lengths_dsp, conf_low_dsp, conf_up_dsp = \\\n",
    "                        data_splitting_poisson(X=X, Y=Y, n=n, p=p, beta=beta, nonzero=nonzero_s,\n",
    "                                               subset_select=selection_idx_s, level=0.9)\n",
    "                    noselection = (coverage_dsp is None)\n",
    "                \"\"\"\n",
    "                if not noselection:\n",
    "                    # data splitting\n",
    "                    coverage_ds, lengths_ds, conf_low_ds, conf_up_ds, nonzero_ds, beta_target_ds = \\\n",
    "                        data_splitting(X=X, Y=Y, n=n, p=p, groups=groups, beta=beta,\n",
    "                                       proportion=0.5, level=0.9)\n",
    "                    noselection = (coverage_ds is None)\n",
    "                    print(\"data splitting noselection:\", noselection)\n",
    "\n",
    "                if not noselection:\n",
    "                    # naive inference\n",
    "                    coverage_naive, lengths_naive, nonzero_naive, conf_low_naive, conf_up_naive, \\\n",
    "                        beta_target_naive = \\\n",
    "                        naive_inference(X=X, Y=Y, groups=groups,\n",
    "                                        beta=beta, const=const,\n",
    "                                        n=n, level=level, nonzero_true=(beta != 0))\n",
    "                    noselection = (coverage_naive is None)\n",
    "                    print(\"naive inference noselection:\", noselection)\n",
    "\n",
    "                if not noselection:\n",
    "                    # F1 scores\n",
    "                    # F1_s = calculate_F1_score(beta, selection=nonzero_s)\n",
    "                    F1 = calculate_F1_score(beta, selection=nonzero)\n",
    "                    F1_ds = calculate_F1_score(beta, selection=nonzero_ds)\n",
    "                    F1_naive = calculate_F1_score(beta, selection=nonzero_naive)\n",
    "                    # F1_p = calculate_F1_score(beta, selection=nonzero_p)\n",
    "                    # F1_dsp = calculate_F1_score(beta, selection=nonzero_s)\n",
    "\n",
    "                    # MLE coverage\n",
    "                    oper_char[\"sparsity size\"].append(s)\n",
    "                    oper_char[\"coverage rate\"].append(np.mean(coverage))\n",
    "                    oper_char[\"avg length\"].append(np.mean(length))\n",
    "                    oper_char[\"F1 score\"].append(F1)\n",
    "                    oper_char[\"method\"].append('MLE')\n",
    "                    df_MLE = pd.concat([pd.DataFrame(np.ones(nonzero.sum()) * i),\n",
    "                                        pd.DataFrame(beta_target),\n",
    "                                        pd.DataFrame(conf_low),\n",
    "                                        pd.DataFrame(conf_up),\n",
    "                                        pd.DataFrame(beta[nonzero] != 0),\n",
    "                                        pd.DataFrame(np.ones(nonzero.sum()) * s),\n",
    "                                        pd.DataFrame(np.ones(nonzero.sum()) * F1),\n",
    "                                        pd.DataFrame([\"MLE\"] * nonzero.sum())\n",
    "                                        ], axis=1)\n",
    "                    confint_df = pd.concat([confint_df, df_MLE], axis=0)\n",
    "\n",
    "                    \"\"\"# Carving coverage\n",
    "                    oper_char[\"sparsity size\"].append(s)\n",
    "                    oper_char[\"coverage rate\"].append(np.mean(coverage_s))\n",
    "                    oper_char[\"avg length\"].append(np.mean(length_s))\n",
    "                    oper_char[\"F1 score\"].append(F1_s)\n",
    "                    oper_char[\"method\"].append('Carving')\n",
    "                    #oper_char[\"runtime\"].append(0)\n",
    "                    df_s = pd.concat([pd.DataFrame(np.ones(nonzero_s.sum()) * i),\n",
    "                                      pd.DataFrame(beta_target_s),\n",
    "                                      pd.DataFrame(conf_low_s),\n",
    "                                      pd.DataFrame(conf_up_s),\n",
    "                                      pd.DataFrame(beta[nonzero_s] != 0),\n",
    "                                      pd.DataFrame(np.ones(nonzero_s.sum()) * s),\n",
    "                                      pd.DataFrame(np.ones(nonzero_s.sum()) * F1_s),\n",
    "                                      pd.DataFrame([\"Carving\"] * nonzero_s.sum())\n",
    "                                      ], axis=1)\n",
    "                    confint_df = pd.concat([confint_df, df_s], axis=0)\"\"\"\n",
    "\n",
    "                    # MLE (Poisson) coverage\n",
    "                    \"\"\"oper_char[\"sparsity size\"].append(s)\n",
    "                    oper_char[\"coverage rate\"].append(np.mean(coverage_p))\n",
    "                    oper_char[\"avg length\"].append(np.mean(length_p))\n",
    "                    oper_char[\"F1 score\"].append(F1_p)\n",
    "                    oper_char[\"method\"].append('MLE (Poisson)')\n",
    "                    df_p = pd.concat([pd.DataFrame(np.ones(nonzero_p.sum()) * i),\n",
    "                                      pd.DataFrame(beta_target_p),\n",
    "                                      pd.DataFrame(conf_low_p),\n",
    "                                      pd.DataFrame(conf_up_p),\n",
    "                                      pd.DataFrame(beta[nonzero_p] != 0),\n",
    "                                      pd.DataFrame(np.ones(nonzero_p.sum()) * s),\n",
    "                                      pd.DataFrame(np.ones(nonzero_p.sum()) * F1_p),\n",
    "                                      pd.DataFrame([\"MLE (Poisson)\"] * nonzero_p.sum())\n",
    "                                      ], axis=1)\n",
    "                    confint_df = pd.concat([confint_df, df_p], axis=0)\"\"\"\n",
    "\n",
    "                    # Data splitting coverage\n",
    "                    oper_char[\"sparsity size\"].append(s)\n",
    "                    oper_char[\"coverage rate\"].append(np.mean(coverage_ds))\n",
    "                    oper_char[\"avg length\"].append(np.mean(lengths_ds))\n",
    "                    oper_char[\"F1 score\"].append(F1_ds)\n",
    "                    oper_char[\"method\"].append('Data splitting')\n",
    "                    df_ds = pd.concat([pd.DataFrame(np.ones(nonzero_ds.sum()) * i),\n",
    "                                       pd.DataFrame(beta_target_ds),\n",
    "                                       pd.DataFrame(conf_low_ds),\n",
    "                                       pd.DataFrame(conf_up_ds),\n",
    "                                       pd.DataFrame(beta[nonzero_ds] != 0),\n",
    "                                       pd.DataFrame(np.ones(nonzero_ds.sum()) * s),\n",
    "                                       pd.DataFrame(np.ones(nonzero_ds.sum()) * F1_ds),\n",
    "                                       pd.DataFrame([\"Data splitting\"] * nonzero_ds.sum())\n",
    "                                       ], axis=1)\n",
    "                    confint_df = pd.concat([confint_df, df_ds], axis=0)\n",
    "\n",
    "                    \"\"\"# Data splitting (poisson) coverage\n",
    "                    oper_char[\"sparsity size\"].append(s)\n",
    "                    oper_char[\"coverage rate\"].append(np.mean(coverage_dsp))\n",
    "                    oper_char[\"avg length\"].append(np.mean(lengths_dsp))\n",
    "                    oper_char[\"F1 score\"].append(F1_dsp)\n",
    "                    oper_char[\"method\"].append('Data splitting (Poisson)')\n",
    "                    df_dsp = pd.concat([pd.DataFrame(np.ones(nonzero_s.sum()) * i),\n",
    "                                       pd.DataFrame(beta_target_s),\n",
    "                                       pd.DataFrame(conf_low_dsp),\n",
    "                                       pd.DataFrame(conf_up_dsp),\n",
    "                                       pd.DataFrame(beta[nonzero_s] != 0),\n",
    "                                       pd.DataFrame(np.ones(nonzero_s.sum()) * s),\n",
    "                                       pd.DataFrame(np.ones(nonzero_s.sum()) * F1_dsp),\n",
    "                                       pd.DataFrame([\"Data splitting (Poisson)\"] * nonzero_s.sum())\n",
    "                                       ], axis=1)\n",
    "                    confint_df = pd.concat([confint_df, df_ds], axis=0)\"\"\"\n",
    "\n",
    "                    # Naive coverage\n",
    "                    oper_char[\"sparsity size\"].append(s)\n",
    "                    oper_char[\"coverage rate\"].append(np.mean(coverage_naive))\n",
    "                    oper_char[\"avg length\"].append(np.mean(lengths_naive))\n",
    "                    oper_char[\"F1 score\"].append(F1_naive)\n",
    "                    oper_char[\"method\"].append('Naive')\n",
    "                    df_naive = pd.concat([pd.DataFrame(np.ones(nonzero_naive.sum()) * i),\n",
    "                                          pd.DataFrame(beta_target_naive),\n",
    "                                          pd.DataFrame(conf_low_naive),\n",
    "                                          pd.DataFrame(conf_up_naive),\n",
    "                                          pd.DataFrame(beta[nonzero_naive] != 0),\n",
    "                                          pd.DataFrame(np.ones(nonzero_naive.sum()) * s),\n",
    "                                          pd.DataFrame(np.ones(nonzero_naive.sum()) * F1_naive),\n",
    "                                          pd.DataFrame([\"Naive\"] * nonzero_naive.sum())\n",
    "                                          ], axis=1)\n",
    "                    confint_df = pd.concat([confint_df, df_naive], axis=0)\n",
    "\n",
    "                    break  # Go to next iteration if we have some selection\n",
    "\n",
    "    oper_char_df = pd.DataFrame.from_dict(oper_char)\n",
    "    oper_char_df.to_csv('selectinf/randomized/tests/quasipois_vary_sparsity.csv', index=False)\n",
    "    colnames = ['Index'] + ['target'] + ['LCB'] + ['UCB'] + ['TP'] + ['sparsity size'] + ['F1'] + ['Method']\n",
    "    confint_df.columns = colnames\n",
    "    confint_df.to_csv('selectinf/randomized/tests/quasipois_CI_vary_sparsity.csv', index=False)\n",
    "\n",
    "    #sns.histplot(oper_char_df[\"sparsity size\"])\n",
    "    #plt.show()\n",
    "\n",
    "    print(\"Mean coverage rate/length:\")\n",
    "    print(oper_char_df.groupby(['sparsity size', 'method']).mean())\n",
    "\n",
    "    sns.boxplot(y=oper_char_df[\"coverage rate\"],\n",
    "                x=oper_char_df[\"sparsity size\"],\n",
    "                hue=oper_char_df[\"method\"],\n",
    "                orient=\"v\")\n",
    "    plt.show()\n",
    "\n",
    "    len_plot = sns.boxplot(y=oper_char_df[\"avg length\"],\n",
    "                           x=oper_char_df[\"sparsity size\"],\n",
    "                           hue=oper_char_df[\"method\"],\n",
    "                           showmeans=True,\n",
    "                           orient=\"v\")\n",
    "    len_plot.set_ylim(0, 8)\n",
    "    plt.show()\n",
    "\n",
    "    F1_plot = sns.boxplot(y=oper_char_df[\"F1 score\"],\n",
    "                          x=oper_char_df[\"sparsity size\"],\n",
    "                          hue=oper_char_df[\"method\"],\n",
    "                          showmeans=True,\n",
    "                          orient=\"v\")\n",
    "    F1_plot.set_ylim(0, 1)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yilingh/Desktop/PhD/SI_Codes/selective-inference/env3/lib/python3.10/site-packages/regreg/smooth/glm.py:1060: RuntimeWarning: divide by zero encountered in log\n",
      "  loss_terms = - coef * ((counts - 1) * np.log(counts))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K_sub norm 17.98783558435469\n",
      "K norm 11.959853142129631\n",
      "K-K_sub norm 10.965677818850976\n",
      "H norm:  7.245240948555767\n",
      "K norm:  3.547130773883981\n",
      "H-K norm:  4.039636602219076\n",
      "Sigma_E norm:  3.371059461642193\n",
      "H^{-1} norm:  6.77932400307741\n",
      "H^{-1}-Sigma_E norm:  3.6741514880433357\n",
      "MLE noselection False\n",
      "(MLE Poisson) H estimated with full model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yilingh/Desktop/PhD/SI_Codes/selective-inference/env3/lib/python3.10/site-packages/regreg/smooth/glm.py:1060: RuntimeWarning: divide by zero encountered in log\n",
      "  loss_terms = - coef * ((counts - 1) * np.log(counts))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Poisson Data Splitting) Selection done without carving\n",
      "(Data Splitting) Selection done without carving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yilingh/Desktop/PhD/SI_Codes/selective-inference/env3/lib/python3.10/site-packages/regreg/smooth/glm.py:1060: RuntimeWarning: divide by zero encountered in log\n",
      "  loss_terms = - coef * ((counts - 1) * np.log(counts))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data splitting |E|: 52\n",
      "DS target: [-0.24145767  0.36506049 -0.03341586 -0.12848683 -0.82474326  1.15162452\n",
      "  1.27997341  1.10929095  0.14240381 -0.19105886  0.32002087  0.06439228\n",
      "  1.48231502  0.6830656   0.76637012  1.17339423 -0.18668681  0.16370619\n",
      "  0.16335968  0.20720938  0.13391004 -0.05692866  0.27029801 -0.05988501\n",
      " -0.19500221  0.30832427 -0.10142513  0.14973693 -0.0377255   0.17891612\n",
      "  0.24564986  0.02637254  0.05580757  0.16200713 -0.15176879 -0.07353469\n",
      "  0.08680516 -0.173031    0.10788324 -0.15252192  0.07821239  0.00291945\n",
      " -0.22782713  0.15234393  0.31029028 -0.05558136 -0.19312388  0.01186284\n",
      "  0.06236497  0.02723099 -0.0988665  -0.38752027]\n",
      "Data splitting noselection False\n",
      "(Naive) True E used\n",
      "Naive selection [False False False False False False False False False False False False\n",
      "  True  True  True  True False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True  True  True  True False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False  True  True  True  True\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      "  True  True  True  True False False False False False False False False\n",
      " False False False False  True  True  True  True]\n",
      "H norm:  5.089601787090725\n",
      "K norm:  4.630343969171238\n",
      "H-K norm:  1.5151553447702122\n",
      "Sigma_E norm:  5.206895968787522\n",
      "H^{-1} norm:  5.697318219409243\n",
      "H^{-1}-Sigma_E norm:  1.6808697417810183\n",
      "Naive noselection False\n",
      "(32, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yilingh/Desktop/PhD/SI_Codes/selective-inference/env3/lib/python3.10/site-packages/regreg/smooth/glm.py:1060: RuntimeWarning: divide by zero encountered in log\n",
      "  loss_terms = - coef * ((counts - 1) * np.log(counts))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K_sub norm 17.786062302691832\n",
      "K norm 10.962328455680183\n",
      "K-K_sub norm 10.533271842798959\n",
      "H norm:  7.385725209614303\n",
      "K norm:  3.4762362553445914\n",
      "H-K norm:  4.221919972352018\n",
      "Sigma_E norm:  3.7736705178718637\n",
      "H^{-1} norm:  7.761595175319626\n",
      "H^{-1}-Sigma_E norm:  4.330459581347976\n",
      "MLE noselection False\n",
      "(MLE Poisson) H estimated with full model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yilingh/Desktop/PhD/SI_Codes/selective-inference/env3/lib/python3.10/site-packages/regreg/smooth/glm.py:1060: RuntimeWarning: divide by zero encountered in log\n",
      "  loss_terms = - coef * ((counts - 1) * np.log(counts))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Poisson Data Splitting) Selection done without carving\n",
      "(Data Splitting) Selection done without carving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yilingh/Desktop/PhD/SI_Codes/selective-inference/env3/lib/python3.10/site-packages/regreg/smooth/glm.py:1060: RuntimeWarning: divide by zero encountered in log\n",
      "  loss_terms = - coef * ((counts - 1) * np.log(counts))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data splitting |E|: 36\n",
      "DS target: [-0.04443731  0.06153943  0.03054874  0.10477677 -0.02355413  0.12693432\n",
      "  0.02979802 -0.20595096  0.00487937  0.57693626  0.05421807 -0.39960983\n",
      " -0.00786418 -0.1711671   0.090231    0.0845021  -0.06051759  0.39632808\n",
      " -0.33457413  0.34134423 -0.11466194 -0.01854218  0.20159236  0.40842487\n",
      " -0.57927123 -0.86990349 -1.04124179  1.02065939 -1.09549031 -1.26611395\n",
      " -0.84523489 -0.93465379  0.20833025 -0.11825915 -0.38295517  0.15842064]\n",
      "Data splitting noselection False\n",
      "(Naive) True E used\n",
      "Naive selection [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      "  True  True  True  True False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True  True  True  True False False False False\n",
      " False False False False False False False False  True  True  True  True\n",
      "  True  True  True  True False False False False False False False False\n",
      "  True  True  True  True False False False False]\n",
      "H norm:  4.982836217035368\n",
      "K norm:  3.9702597322157924\n",
      "H-K norm:  1.4041598673871825\n",
      "Sigma_E norm:  4.48369101343377\n",
      "H^{-1} norm:  5.71386557533104\n",
      "H^{-1}-Sigma_E norm:  1.6466421803784201\n",
      "Naive noselection False\n",
      "(36, 36)\n",
      "K_sub norm 17.880526134449596\n",
      "K norm 11.138681146332772\n",
      "K-K_sub norm 10.686194172844472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yilingh/Desktop/PhD/SI_Codes/selective-inference/env3/lib/python3.10/site-packages/regreg/smooth/glm.py:1060: RuntimeWarning: divide by zero encountered in log\n",
      "  loss_terms = - coef * ((counts - 1) * np.log(counts))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H norm:  8.684144714097322\n",
      "K norm:  4.026741582828068\n",
      "H-K norm:  5.072528913905054\n",
      "Sigma_E norm:  3.9808464389558122\n",
      "H^{-1} norm:  8.33025840232899\n",
      "H^{-1}-Sigma_E norm:  4.70963864672126\n",
      "MLE noselection False\n",
      "(MLE Poisson) H estimated with full model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yilingh/Desktop/PhD/SI_Codes/selective-inference/env3/lib/python3.10/site-packages/regreg/smooth/glm.py:1060: RuntimeWarning: divide by zero encountered in log\n",
      "  loss_terms = - coef * ((counts - 1) * np.log(counts))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Poisson Data Splitting) Selection done without carving\n",
      "(Data Splitting) Selection done without carving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yilingh/Desktop/PhD/SI_Codes/selective-inference/env3/lib/python3.10/site-packages/regreg/smooth/glm.py:1060: RuntimeWarning: divide by zero encountered in log\n",
      "  loss_terms = - coef * ((counts - 1) * np.log(counts))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data splitting |E|: 56\n",
      "DS target: [ 0.1161046  -0.09287678 -0.15220767  0.13248885 -0.15585853  0.06895558\n",
      " -0.08742536  0.02672686  1.01392801  1.10830437 -0.97179868 -1.20396116\n",
      " -0.14398076  0.09335805  0.19107722 -0.21350735  0.1338954  -0.06499824\n",
      "  0.07130226  0.04648435  0.98426854  1.09087689  1.08358774  1.03169453\n",
      " -0.12848652  0.01659877 -0.01546706  0.16608438 -0.87357516 -1.23044927\n",
      "  0.94642066  1.13566559 -0.08858776 -0.0058476   0.1656126  -0.17066582\n",
      "  0.14905878 -0.2959545   0.14181325  0.06892825  0.07234258 -0.14919119\n",
      "  0.06807096  0.07275136 -0.07850597  0.06724832 -0.12147402 -0.17665268\n",
      " -0.17742348 -0.14105177  0.07403654 -0.07253319  1.27117531  0.92597696\n",
      "  0.84060464  1.36960559]\n",
      "Data splitting noselection False\n",
      "(Naive) True E used\n",
      "Naive selection [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True  True  True  True False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      "  True  True  True  True False False False False False False False False\n",
      "  True  True  True  True False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True  True  True  True False False False False\n",
      "  True  True  True  True False False False False]\n",
      "H norm:  5.251335080356725\n",
      "K norm:  4.7654875526067375\n",
      "H-K norm:  1.4250795283351854\n",
      "Sigma_E norm:  4.8773458352191446\n",
      "H^{-1} norm:  5.464152177088057\n",
      "H^{-1}-Sigma_E norm:  1.7349709857655433\n",
      "Naive noselection False\n",
      "(44, 44)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yilingh/Desktop/PhD/SI_Codes/selective-inference/env3/lib/python3.10/site-packages/regreg/smooth/glm.py:1060: RuntimeWarning: divide by zero encountered in log\n",
      "  loss_terms = - coef * ((counts - 1) * np.log(counts))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K_sub norm 17.919244706185424\n",
      "K norm 14.089833267456719\n",
      "K-K_sub norm 10.371543068458436\n",
      "H norm:  7.332446655307668\n",
      "K norm:  4.333017862219469\n",
      "H-K norm:  3.5126987733127164\n",
      "Sigma_E norm:  4.1102913668049945\n",
      "H^{-1} norm:  6.750122456205752\n",
      "H^{-1}-Sigma_E norm:  3.056370353014814\n",
      "MLE noselection False\n",
      "(MLE Poisson) H estimated with full model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yilingh/Desktop/PhD/SI_Codes/selective-inference/env3/lib/python3.10/site-packages/regreg/smooth/glm.py:1060: RuntimeWarning: divide by zero encountered in log\n",
      "  loss_terms = - coef * ((counts - 1) * np.log(counts))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Poisson Data Splitting) Selection done without carving\n",
      "(Data Splitting) Selection done without carving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yilingh/Desktop/PhD/SI_Codes/selective-inference/env3/lib/python3.10/site-packages/regreg/smooth/glm.py:1060: RuntimeWarning: divide by zero encountered in log\n",
      "  loss_terms = - coef * ((counts - 1) * np.log(counts))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data splitting |E|: 24\n",
      "DS target: [-4.96054865e-03  7.68098497e-02 -3.49493951e-02  2.55238355e-01\n",
      "  3.35326363e-02 -3.43617832e-02  4.51373020e-04  3.55652346e-01\n",
      "  4.51353358e-01  1.08657103e+00  8.82452580e-01  1.15436559e+00\n",
      "  3.21068073e-02 -2.61172402e-01 -5.14467649e-02  7.08740397e-02\n",
      "  1.73162183e-01 -1.31144316e-01  1.25479828e-01  1.87885509e-01\n",
      " -1.07311796e+00  8.56915942e-01  9.64862805e-01 -1.19048965e+00]\n",
      "Data splitting noselection False\n",
      "(Naive) True E used\n",
      "Naive selection [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False  True  True  True  True\n",
      "  True  True  True  True False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True  True  True  True False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      "  True  True  True  True False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      "  True  True  True  True False False False False]\n",
      "H norm:  5.052092331251776\n",
      "K norm:  5.543052539523191\n",
      "H-K norm:  1.3572892303443664\n",
      "Sigma_E norm:  5.9863613857948526\n",
      "H^{-1} norm:  5.496189312020993\n",
      "H^{-1}-Sigma_E norm:  1.592196064569745\n",
      "Naive noselection False\n",
      "(32, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yilingh/Desktop/PhD/SI_Codes/selective-inference/env3/lib/python3.10/site-packages/regreg/smooth/glm.py:1060: RuntimeWarning: divide by zero encountered in log\n",
      "  loss_terms = - coef * ((counts - 1) * np.log(counts))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K_sub norm 17.879883540054458\n",
      "K norm 11.950182859373495\n",
      "K-K_sub norm 10.826040965375125\n",
      "H norm:  7.702495744179027\n",
      "K norm:  3.8042411080356735\n",
      "H-K norm:  4.304059727312747\n",
      "Sigma_E norm:  3.980315577982751\n",
      "H^{-1} norm:  7.503585018633304\n",
      "H^{-1}-Sigma_E norm:  3.949923501665693\n",
      "MLE noselection False\n",
      "(MLE Poisson) H estimated with full model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yilingh/Desktop/PhD/SI_Codes/selective-inference/env3/lib/python3.10/site-packages/regreg/smooth/glm.py:1060: RuntimeWarning: divide by zero encountered in log\n",
      "  loss_terms = - coef * ((counts - 1) * np.log(counts))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Poisson Data Splitting) Selection done without carving\n",
      "(Data Splitting) Selection done without carving\n",
      "Data splitting |E|: 52\n",
      "DS target: [ 0.1233414   0.15256789  0.00761309 -0.03582425  0.09074546  0.01505378\n",
      " -0.43601112 -0.09605639  0.51382434  0.1504035  -0.22096705  0.01283121\n",
      "  0.00390419  0.20066182 -0.15931788  0.27770551  0.47106386  0.30062931\n",
      "  0.08021036 -0.25136418  0.72952344 -0.07678687 -0.16383992  0.22851529\n",
      "  0.00618316  0.03265879  0.20659802 -0.11084695 -0.25923803 -0.12678579\n",
      "  0.59086493 -0.36806438 -0.50893753  0.30017826 -0.1843778  -0.08853168\n",
      " -0.14583517 -0.03264648 -0.1412891  -0.38261172  0.18126915  0.05441281\n",
      " -0.16675047 -0.12471639 -0.67255089 -1.15535025  0.85547338  1.5584803\n",
      "  0.11038235 -0.1815001  -0.15983737  0.50070453]\n",
      "Data splitting noselection False\n",
      "(Naive) True E used\n",
      "Naive selection [False False False False False False False False  True  True  True  True\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False  True  True  True  True\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      "  True  True  True  True False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True  True  True  True False False False False\n",
      " False False False False False False False False  True  True  True  True\n",
      " False False False False False False False False]\n",
      "H norm:  5.031514040723084\n",
      "K norm:  4.901996666363268\n",
      "H-K norm:  1.4366773960524377\n",
      "Sigma_E norm:  6.021300087601139\n",
      "H^{-1} norm:  5.7250314620911436\n",
      "H^{-1}-Sigma_E norm:  1.8592999350754642\n",
      "Naive noselection False\n",
      "(36, 36)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yilingh/Desktop/PhD/SI_Codes/selective-inference/env3/lib/python3.10/site-packages/regreg/smooth/glm.py:1060: RuntimeWarning: divide by zero encountered in log\n",
      "  loss_terms = - coef * ((counts - 1) * np.log(counts))\n",
      "/Users/yilingh/Desktop/PhD/SI_Codes/selective-inference/env3/lib/python3.10/site-packages/regreg/smooth/glm.py:1060: RuntimeWarning: divide by zero encountered in log\n",
      "  loss_terms = - coef * ((counts - 1) * np.log(counts))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K_sub norm 17.92932619641641\n",
      "K norm 12.946432496181844\n",
      "K-K_sub norm 10.223717477489842\n",
      "H norm:  7.432341366977368\n",
      "K norm:  3.8940161927002817\n",
      "H-K norm:  3.856072687351661\n",
      "Sigma_E norm:  3.7680549460282835\n",
      "H^{-1} norm:  6.749779903380575\n",
      "H^{-1}-Sigma_E norm:  3.307599040320487\n",
      "MLE noselection False\n",
      "(MLE Poisson) H estimated with full model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yilingh/Desktop/PhD/SI_Codes/selective-inference/env3/lib/python3.10/site-packages/regreg/smooth/glm.py:1060: RuntimeWarning: divide by zero encountered in log\n",
      "  loss_terms = - coef * ((counts - 1) * np.log(counts))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Poisson Data Splitting) Selection done without carving\n",
      "(Data Splitting) Selection done without carving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yilingh/Desktop/PhD/SI_Codes/selective-inference/env3/lib/python3.10/site-packages/regreg/smooth/glm.py:1060: RuntimeWarning: divide by zero encountered in log\n",
      "  loss_terms = - coef * ((counts - 1) * np.log(counts))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data splitting |E|: 28\n",
      "DS target: [-0.16770366 -0.03252391  0.28329943 -0.23658828 -0.42226892 -0.02247229\n",
      " -0.13716904  0.27321897 -1.10044434  0.94010983 -0.83786467 -1.29927483\n",
      "  1.13443415  1.01728677  1.02813817  1.17567576 -0.91508475  0.93267315\n",
      " -1.00607159 -1.01917434  0.05500752 -0.02343207  0.11518994  0.16044629\n",
      "  0.13335658  0.42919925 -0.13778315  0.13395821]\n",
      "Data splitting noselection False\n",
      "(Naive) True E used\n",
      "Naive selection [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True  True  True  True False False False False\n",
      " False False False False  True  True  True  True False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      "  True  True  True  True False False False False False False False False\n",
      " False False False False  True  True  True  True False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False  True  True  True  True\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "H norm:  4.999660578927732\n",
      "K norm:  4.968199532002771\n",
      "H-K norm:  1.2205757487901938\n",
      "Sigma_E norm:  5.2404783441458145\n",
      "H^{-1} norm:  5.562702228890883\n",
      "H^{-1}-Sigma_E norm:  1.4618409840740612\n",
      "Naive noselection False\n",
      "(32, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yilingh/Desktop/PhD/SI_Codes/selective-inference/env3/lib/python3.10/site-packages/regreg/smooth/glm.py:1060: RuntimeWarning: divide by zero encountered in log\n",
      "  loss_terms = - coef * ((counts - 1) * np.log(counts))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K_sub norm 17.922712000244324\n",
      "K norm 12.782557022868982\n",
      "K-K_sub norm 11.06524151302513\n",
      "H norm:  4.937914690637781\n",
      "K norm:  2.5355497902765447\n",
      "H-K norm:  2.570400276126801\n",
      "Sigma_E norm:  2.527462770663386\n",
      "H^{-1} norm:  4.776690448262671\n",
      "H^{-1}-Sigma_E norm:  2.408802979820016\n",
      "MLE noselection False\n",
      "(MLE Poisson) H estimated with full model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yilingh/Desktop/PhD/SI_Codes/selective-inference/env3/lib/python3.10/site-packages/regreg/smooth/glm.py:1060: RuntimeWarning: divide by zero encountered in log\n",
      "  loss_terms = - coef * ((counts - 1) * np.log(counts))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Poisson Data Splitting) Selection done without carving\n",
      "(Data Splitting) Selection done without carving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yilingh/Desktop/PhD/SI_Codes/selective-inference/env3/lib/python3.10/site-packages/regreg/smooth/glm.py:1060: RuntimeWarning: divide by zero encountered in log\n",
      "  loss_terms = - coef * ((counts - 1) * np.log(counts))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data splitting |E|: 32\n",
      "DS target: [-0.20753094 -0.0584422  -0.02576913  0.27447747 -0.3477532   0.37062021\n",
      "  0.03194862  0.09319926  0.12758117  0.06388318 -0.0184478   0.08374821\n",
      " -0.07997099  0.34997144 -0.20617089 -0.25668823  1.41940774 -1.28679662\n",
      " -1.08288577 -0.91964109 -0.16275071  0.14669603  0.16639175 -0.38923178\n",
      "  0.08734599  0.04383838  0.32340014 -0.13010969  0.04843141  0.0192914\n",
      " -0.08413467  0.22399967]\n",
      "Data splitting noselection False\n",
      "(Naive) True E used\n",
      "Naive selection [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True  True  True  True False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      "  True  True  True  True False False False False  True  True  True  True\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False  True  True  True  True\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True  True  True  True False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "H norm:  4.956576649292601\n",
      "K norm:  4.728620369755275\n",
      "H-K norm:  1.4761732381041506\n",
      "Sigma_E norm:  5.830493599369313\n",
      "H^{-1} norm:  5.872469070870751\n",
      "H^{-1}-Sigma_E norm:  1.7758522829888594\n",
      "Naive noselection False\n",
      "(16, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yilingh/Desktop/PhD/SI_Codes/selective-inference/env3/lib/python3.10/site-packages/regreg/smooth/glm.py:1060: RuntimeWarning: divide by zero encountered in log\n",
      "  loss_terms = - coef * ((counts - 1) * np.log(counts))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K_sub norm 17.944741453504594\n",
      "K norm 11.887856261057369\n",
      "K-K_sub norm 10.435037476076642\n",
      "H norm:  7.0549757021057635\n",
      "K norm:  3.650801141473534\n",
      "H-K norm:  3.727849182466447\n",
      "Sigma_E norm:  3.7831837503749663\n",
      "H^{-1} norm:  7.062937212710426\n",
      "H^{-1}-Sigma_E norm:  3.5831571764577332\n",
      "MLE noselection False\n",
      "(MLE Poisson) H estimated with full model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yilingh/Desktop/PhD/SI_Codes/selective-inference/env3/lib/python3.10/site-packages/regreg/smooth/glm.py:1060: RuntimeWarning: divide by zero encountered in log\n",
      "  loss_terms = - coef * ((counts - 1) * np.log(counts))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Poisson Data Splitting) Selection done without carving\n",
      "(Data Splitting) Selection done without carving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yilingh/Desktop/PhD/SI_Codes/selective-inference/env3/lib/python3.10/site-packages/regreg/smooth/glm.py:1060: RuntimeWarning: divide by zero encountered in log\n",
      "  loss_terms = - coef * ((counts - 1) * np.log(counts))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data splitting |E|: 56\n",
      "DS target: [ 0.09577687  0.05087571  0.21353873 -0.13858301 -1.10179613 -0.6111645\n",
      "  1.06081271  1.07768398  0.17610207 -0.15507985 -0.04712073  0.36980999\n",
      " -0.35031153 -0.02507095 -0.01732244  0.16973556 -0.36760681  0.15276442\n",
      "  0.31177365 -0.23198534 -0.28304008 -0.0695614   0.28135765 -0.14280275\n",
      " -0.18023164 -0.07630195  0.04668243  0.06234651  0.30256367 -0.08418791\n",
      "  0.16170797 -0.06041242  0.01786972 -0.35342651  0.17694817  0.03729327\n",
      "  0.21067889 -0.02269091  0.43130517 -0.0157793   0.00686484  0.22021269\n",
      " -0.18361126  0.07468683 -0.14412202 -0.22745312  0.13437601  0.04229834\n",
      "  0.05996651 -0.19258613 -0.18973686 -0.0137287   0.00763226  0.16801442\n",
      " -0.15893907 -0.12328983]\n",
      "Data splitting noselection False\n",
      "(Naive) True E used\n",
      "Naive selection [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      "  True  True  True  True False False False False  True  True  True  True\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      "  True  True  True  True False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True  True  True  True  True  True  True  True\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "H norm:  5.093349776205271\n",
      "K norm:  5.107216027251607\n",
      "H-K norm:  1.6624128813764851\n",
      "Sigma_E norm:  5.239638166442214\n",
      "H^{-1} norm:  5.579162818222412\n",
      "H^{-1}-Sigma_E norm:  1.6669373771730172\n",
      "Naive noselection False\n",
      "(32, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yilingh/Desktop/PhD/SI_Codes/selective-inference/env3/lib/python3.10/site-packages/regreg/smooth/glm.py:1060: RuntimeWarning: divide by zero encountered in log\n",
      "  loss_terms = - coef * ((counts - 1) * np.log(counts))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K_sub norm 17.913504953308333\n",
      "K norm 15.385571947888867\n",
      "K-K_sub norm 11.052495339447077\n",
      "H norm:  5.478301635032989\n",
      "K norm:  3.491149655211313\n",
      "H-K norm:  2.280629653053758\n",
      "Sigma_E norm:  3.267949342296482\n",
      "H^{-1} norm:  5.3123089205514855\n",
      "H^{-1}-Sigma_E norm:  2.3515906646731626\n",
      "MLE noselection False\n",
      "(MLE Poisson) H estimated with full model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yilingh/Desktop/PhD/SI_Codes/selective-inference/env3/lib/python3.10/site-packages/regreg/smooth/glm.py:1060: RuntimeWarning: divide by zero encountered in log\n",
      "  loss_terms = - coef * ((counts - 1) * np.log(counts))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Poisson Data Splitting) Selection done without carving\n",
      "(Data Splitting) Selection done without carving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yilingh/Desktop/PhD/SI_Codes/selective-inference/env3/lib/python3.10/site-packages/regreg/smooth/glm.py:1060: RuntimeWarning: divide by zero encountered in log\n",
      "  loss_terms = - coef * ((counts - 1) * np.log(counts))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data splitting |E|: 28\n",
      "DS target: [-0.07164365  0.17952994  0.04778583 -0.4367358   0.38649782 -0.43134501\n",
      " -0.24662847  0.34712219 -0.1605141  -0.28641715 -0.08340705 -0.05402948\n",
      " -0.09390755 -0.19952397 -0.15692282 -0.0541595  -0.06761213 -0.03930582\n",
      " -0.21541886  0.21594304 -0.57356671  0.12422443  0.21377177 -0.25010974\n",
      "  1.34607338 -1.00574129  0.94073807  1.04377842]\n",
      "Data splitting noselection False\n",
      "(Naive) True E used\n",
      "Naive selection [ True  True  True  True False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      "  True  True  True  True False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False  True  True  True  True\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False  True  True  True  True  True  True  True  True\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "H norm:  5.040091342568935\n",
      "K norm:  5.3613967948367485\n",
      "H-K norm:  1.509238400427191\n",
      "Sigma_E norm:  6.239420721535088\n",
      "H^{-1} norm:  5.657167183168526\n",
      "H^{-1}-Sigma_E norm:  2.022077834533885\n",
      "Naive noselection False\n",
      "(20, 20)\n",
      "K_sub norm 17.88623429113563\n",
      "K norm 11.915589312858417\n",
      "K-K_sub norm 10.460886792308202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yilingh/Desktop/PhD/SI_Codes/selective-inference/env3/lib/python3.10/site-packages/regreg/smooth/glm.py:1060: RuntimeWarning: divide by zero encountered in log\n",
      "  loss_terms = - coef * ((counts - 1) * np.log(counts))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H norm:  4.223432877627024\n",
      "K norm:  2.0922045797668822\n",
      "H-K norm:  2.2058713211910077\n",
      "Sigma_E norm:  1.9933455439757568\n",
      "H^{-1} norm:  3.843244783812603\n",
      "H^{-1}-Sigma_E norm:  1.9317785522571296\n",
      "MLE noselection False\n",
      "(MLE Poisson) H estimated with full model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yilingh/Desktop/PhD/SI_Codes/selective-inference/env3/lib/python3.10/site-packages/regreg/smooth/glm.py:1060: RuntimeWarning: divide by zero encountered in log\n",
      "  loss_terms = - coef * ((counts - 1) * np.log(counts))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Poisson Data Splitting) Selection done without carving\n",
      "(Data Splitting) Selection done without carving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yilingh/Desktop/PhD/SI_Codes/selective-inference/env3/lib/python3.10/site-packages/regreg/smooth/glm.py:1060: RuntimeWarning: divide by zero encountered in log\n",
      "  loss_terms = - coef * ((counts - 1) * np.log(counts))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data splitting |E|: 44\n",
      "DS target: [ 0.80967929 -0.82428974 -1.02277999 -1.1184978  -0.33032268  0.41307328\n",
      " -0.302854    0.08450958  0.1729138  -0.15687345  0.16435785  0.10918\n",
      "  0.3494047  -0.04967008 -0.49735694  0.11287507  0.19795924 -0.25589319\n",
      " -0.07882197  0.05470966  0.07129089 -0.15993641 -0.27394547  0.39808758\n",
      "  0.2776109  -0.13160341  0.19655907  0.07764964 -0.31978738  0.14510466\n",
      "  0.1000515   0.12258585  0.16859646  0.20726878  0.06215516 -0.10406137\n",
      "  0.17588498  0.16325338  0.14566285 -0.10890534  0.02694496  0.32897453\n",
      " -0.4148493   0.14880984]\n",
      "Data splitting noselection False\n",
      "(Naive) True E used\n",
      "Naive selection [False False False False  True  True  True  True False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      "  True  True  True  True False False False False  True  True  True  True\n",
      " False False False False  True  True  True  True False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False  True  True  True  True\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "H norm:  5.000527820252153\n",
      "K norm:  4.222141289345388\n",
      "H-K norm:  1.2519522240539582\n",
      "Sigma_E norm:  4.873894528178285\n",
      "H^{-1} norm:  5.700338346270323\n",
      "H^{-1}-Sigma_E norm:  1.4058171366657435\n",
      "Naive noselection False\n",
      "(12, 12)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yilingh/Desktop/PhD/SI_Codes/selective-inference/env3/lib/python3.10/site-packages/regreg/smooth/glm.py:1060: RuntimeWarning: divide by zero encountered in log\n",
      "  loss_terms = - coef * ((counts - 1) * np.log(counts))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K_sub norm 17.883253384951363\n",
      "K norm 12.677201270669372\n",
      "K-K_sub norm 10.8804795325651\n",
      "H norm:  4.98982754899943\n",
      "K norm:  2.749530446074605\n",
      "H-K norm:  2.3852423045236937\n",
      "Sigma_E norm:  2.469906387561875\n",
      "H^{-1} norm:  4.633542695159421\n",
      "H^{-1}-Sigma_E norm:  2.2904833749824363\n",
      "MLE noselection False\n",
      "(MLE Poisson) H estimated with full model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yilingh/Desktop/PhD/SI_Codes/selective-inference/env3/lib/python3.10/site-packages/regreg/smooth/glm.py:1060: RuntimeWarning: divide by zero encountered in log\n",
      "  loss_terms = - coef * ((counts - 1) * np.log(counts))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Poisson Data Splitting) Selection done without carving\n",
      "(Data Splitting) Selection done without carving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yilingh/Desktop/PhD/SI_Codes/selective-inference/env3/lib/python3.10/site-packages/regreg/smooth/glm.py:1060: RuntimeWarning: divide by zero encountered in log\n",
      "  loss_terms = - coef * ((counts - 1) * np.log(counts))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtest_comparison_quasipoisson_group_lasso_vary_s\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/PhD/SI_Codes/selective-inference/selectinf/randomized/tests/test_quasipoisson_group_lasso.py:1019\u001B[0m, in \u001B[0;36mtest_comparison_quasipoisson_group_lasso_vary_s\u001B[0;34m(n, p, signal_fac, s, sigma, rho, randomizer_scale, full_dispersion, level, iter)\u001B[0m\n\u001B[1;32m   1014\u001B[0m     noselection \u001B[38;5;241m=\u001B[39m (coverage_dsp \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m   1016\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m noselection:\n\u001B[1;32m   1017\u001B[0m     \u001B[38;5;66;03m# data splitting\u001B[39;00m\n\u001B[1;32m   1018\u001B[0m     coverage_ds, lengths_ds, conf_low_ds, conf_up_ds, nonzero_ds, beta_target_ds \u001B[38;5;241m=\u001B[39m \\\n\u001B[0;32m-> 1019\u001B[0m         \u001B[43mdata_splitting\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mY\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconst\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconst\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroups\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbeta\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1020\u001B[0m \u001B[43m                       \u001B[49m\u001B[43mproportion\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlevel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.9\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1021\u001B[0m     noselection \u001B[38;5;241m=\u001B[39m (coverage_ds \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m   1022\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mData splitting noselection\u001B[39m\u001B[38;5;124m\"\u001B[39m, noselection)\n",
      "File \u001B[0;32m~/Desktop/PhD/SI_Codes/selective-inference/selectinf/randomized/tests/test_quasipoisson_group_lasso.py:622\u001B[0m, in \u001B[0;36mdata_splitting\u001B[0;34m(X, Y, n, p, const, beta, nonzero, subset_select, groups, weight_frac, proportion, level)\u001B[0m\n\u001B[1;32m    612\u001B[0m weights \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m([(i, (n1\u001B[38;5;241m/\u001B[39mn)\u001B[38;5;241m*\u001B[39mweight_frac \u001B[38;5;241m*\u001B[39m sigma_ \u001B[38;5;241m*\u001B[39m np\u001B[38;5;241m.\u001B[39msqrt(\u001B[38;5;241m2\u001B[39m \u001B[38;5;241m*\u001B[39m np\u001B[38;5;241m.\u001B[39mlog(p))) \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m np\u001B[38;5;241m.\u001B[39munique(groups)])\n\u001B[1;32m    614\u001B[0m conv \u001B[38;5;241m=\u001B[39m const(X\u001B[38;5;241m=\u001B[39mX_S,\n\u001B[1;32m    615\u001B[0m              counts\u001B[38;5;241m=\u001B[39mY_S,\n\u001B[1;32m    616\u001B[0m              groups\u001B[38;5;241m=\u001B[39mgroups,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    619\u001B[0m              perturb\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mzeros(p),\n\u001B[1;32m    620\u001B[0m              ridge_term\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.\u001B[39m)\n\u001B[0;32m--> 622\u001B[0m signs, _ \u001B[38;5;241m=\u001B[39m \u001B[43mconv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    623\u001B[0m \u001B[38;5;66;03m# print(\"signs\",  signs)\u001B[39;00m\n\u001B[1;32m    624\u001B[0m nonzero \u001B[38;5;241m=\u001B[39m signs \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "File \u001B[0;32m~/Desktop/PhD/SI_Codes/selective-inference/selectinf/randomized/group_lasso_query_quasi.py:151\u001B[0m, in \u001B[0;36mgroup_lasso_quasi.fit\u001B[0;34m(self, solve_args, perturb)\u001B[0m\n\u001B[1;32m    145\u001B[0m n, p \u001B[38;5;241m=\u001B[39m X\u001B[38;5;241m.\u001B[39mshape\n\u001B[1;32m    146\u001B[0m \u001B[38;5;66;03m# --------------------------- TO BE UNCOMMENTED -------------------------------\u001B[39;00m\n\u001B[1;32m    147\u001B[0m \u001B[38;5;66;03m# W = self._W = self.loglike.saturated_loss.hessian(X.dot(beta_bar))  # all 1's for LS\u001B[39;00m\n\u001B[1;32m    148\u001B[0m \u001B[38;5;66;03m# --------------------------- TO BE UNCOMMENTED -------------------------------\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \n\u001B[1;32m    150\u001B[0m \u001B[38;5;66;03m# FULL MLE:\u001B[39;00m\n\u001B[0;32m--> 151\u001B[0m beta_MLE_full \u001B[38;5;241m=\u001B[39m \u001B[43mrestricted_estimator\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloglike\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# refit OLS (MLE)\u001B[39;49;00m\n\u001B[1;32m    152\u001B[0m \u001B[43m                                     \u001B[49m\u001B[43mactive\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43marray\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnfeature\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    153\u001B[0m \u001B[43m                                     \u001B[49m\u001B[43msolve_args\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msolve_args\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    154\u001B[0m mu_hat_full \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mexp(X \u001B[38;5;241m@\u001B[39m beta_MLE_full)\n\u001B[1;32m    155\u001B[0m \u001B[38;5;66;03m# --------------------------- TO BE COMMENTED -------------------------------\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/PhD/SI_Codes/selective-inference/selectinf/base.py:42\u001B[0m, in \u001B[0;36mrestricted_estimator\u001B[0;34m(loss, active, solve_args)\u001B[0m\n\u001B[1;32m     40\u001B[0m     I_restricted \u001B[38;5;241m=\u001B[39m ra\u001B[38;5;241m.\u001B[39mselector(active, ra\u001B[38;5;241m.\u001B[39mastransform(X)\u001B[38;5;241m.\u001B[39minput_shape[\u001B[38;5;241m0\u001B[39m], ra\u001B[38;5;241m.\u001B[39midentity((active\u001B[38;5;241m.\u001B[39msum(),)))\n\u001B[1;32m     41\u001B[0m     loss_restricted \u001B[38;5;241m=\u001B[39m rr\u001B[38;5;241m.\u001B[39maffine_smooth(loss, I_restricted\u001B[38;5;241m.\u001B[39mT)\n\u001B[0;32m---> 42\u001B[0m beta_E \u001B[38;5;241m=\u001B[39m \u001B[43mloss_restricted\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msolve\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43msolve_args\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     44\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m beta_E\n",
      "File \u001B[0;32m~/Desktop/PhD/SI_Codes/selective-inference/env3/lib/python3.10/site-packages/regreg/problems/composite.py:218\u001B[0m, in \u001B[0;36msmooth.solve\u001B[0;34m(self, quadratic, return_optimum, **fit_args)\u001B[0m\n\u001B[1;32m    216\u001B[0m oldq, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mquadratic \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mquadratic, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mquadratic \u001B[38;5;241m+\u001B[39m quadratic\n\u001B[1;32m    217\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msolver \u001B[38;5;241m=\u001B[39m FISTA(\u001B[38;5;28mself\u001B[39m)\n\u001B[0;32m--> 218\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msolver\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_args\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    219\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mquadratic \u001B[38;5;241m=\u001B[39m oldq\n\u001B[1;32m    221\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m return_optimum:\n",
      "File \u001B[0;32m~/Desktop/PhD/SI_Codes/selective-inference/env3/lib/python3.10/site-packages/regreg/algorithms.py:131\u001B[0m, in \u001B[0;36mFISTA.fit\u001B[0;34m(self, tol, min_its, max_its, FISTA, start_step, restart, coef_stop, return_objective_hist, monotonicity_restart, debug, prox_control)\u001B[0m\n\u001B[1;32m    129\u001B[0m \u001B[38;5;66;03m# Backtracking loop\u001B[39;00m\n\u001B[1;32m    130\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mperform_backtrack:\n\u001B[0;32m--> 131\u001B[0m     proposed_coefs, proposed_smooth \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbacktrack\u001B[49m\u001B[43m(\u001B[49m\u001B[43mitercount\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    133\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    134\u001B[0m     \u001B[38;5;66;03m#Use specified Lipschitz constant\u001B[39;00m\n\u001B[1;32m    135\u001B[0m     working_grad \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcomposite\u001B[38;5;241m.\u001B[39msmooth_objective(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mworking_coefs, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgrad\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/Desktop/PhD/SI_Codes/selective-inference/env3/lib/python3.10/site-packages/regreg/algorithms.py:233\u001B[0m, in \u001B[0;36mFISTA.backtrack\u001B[0;34m(self, itercount)\u001B[0m\n\u001B[1;32m    231\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstep \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39malpha\n\u001B[1;32m    232\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mattempt_decrease \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m--> 233\u001B[0m working_smooth, working_grad \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcomposite\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msmooth_objective\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mworking_coefs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mboth\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    234\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m    235\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprox_control \u001B[38;5;241m!=\u001B[39m {}:\n",
      "File \u001B[0;32m~/Desktop/PhD/SI_Codes/selective-inference/env3/lib/python3.10/site-packages/regreg/smooth/__init__.py:235\u001B[0m, in \u001B[0;36maffine_smooth.smooth_objective\u001B[0;34m(self, arg, mode, check_feasibility)\u001B[0m\n\u001B[1;32m    209\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msmooth_objective\u001B[39m(\u001B[38;5;28mself\u001B[39m, arg, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mboth\u001B[39m\u001B[38;5;124m'\u001B[39m, check_feasibility\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m    210\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    211\u001B[0m \u001B[38;5;124;03m    Compute the smooth objective at the point `self.transform.affine_map(arg)`.\u001B[39;00m\n\u001B[1;32m    212\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    232\u001B[0m \u001B[38;5;124;03m    else returns both.\u001B[39;00m\n\u001B[1;32m    233\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 235\u001B[0m     eta \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maffine_transform\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maffine_map\u001B[49m\u001B[43m(\u001B[49m\u001B[43marg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    236\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mboth\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    237\u001B[0m         v, g \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39matom\u001B[38;5;241m.\u001B[39msmooth_objective(eta, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mboth\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/Desktop/PhD/SI_Codes/selective-inference/env3/lib/python3.10/site-packages/regreg/affine/__init__.py:220\u001B[0m, in \u001B[0;36maffine_transform.affine_map\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    218\u001B[0m     v \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlinear_operator\u001B[38;5;241m.\u001B[39maffine_map(x)\n\u001B[1;32m    219\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 220\u001B[0m     v \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear_map\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    221\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maffine_offset \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    222\u001B[0m     \u001B[38;5;66;03m# Deal with 1D and 2D input, affine_offset cases\u001B[39;00m\n\u001B[1;32m    223\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m broadcast_first(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maffine_offset, v, add)\n",
      "File \u001B[0;32m~/Desktop/PhD/SI_Codes/selective-inference/env3/lib/python3.10/site-packages/regreg/affine/__init__.py:155\u001B[0m, in \u001B[0;36maffine_transform.linear_map\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    152\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdiagD:\n\u001B[1;32m    153\u001B[0m     \u001B[38;5;66;03m# Deal with 1D or 2D input or linear operator\u001B[39;00m\n\u001B[1;32m    154\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m broadcast_first(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlinear_operator, x, mul)\n\u001B[0;32m--> 155\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear_operator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdot\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "test_comparison_quasipoisson_group_lasso_vary_s()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
